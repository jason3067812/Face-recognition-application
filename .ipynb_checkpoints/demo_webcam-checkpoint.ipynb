{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46b403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from models.detector import face_detector\n",
    "from models.detector.iris_detector import IrisDetector\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb2da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jason\\anaconda3\\envs\\keras224\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "fd = face_detector.FaceAlignmentDetector(\n",
    "    lmd_weights_path=\"./models/detector/FAN/2DFAN-4_keras.h5\",\n",
    "     fd_type=\"s3fd\"\n",
    "    # 2DFAN-4_keras.h5, 2DFAN-1_keras.h5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca3503",
   "metadata": {},
   "source": [
    "## warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45b1816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize image to (768, 432).\n",
      "Building FAN for landmarks detection...\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def resize_image(im, max_size=768):\n",
    "    if np.max(im.shape) > max_size:\n",
    "        ratio = max_size / np.max(im.shape)\n",
    "        print(f\"Resize image to ({str(int(im.shape[1]*ratio))}, {str(int(im.shape[0]*ratio))}).\")\n",
    "        return cv2.resize(im, (0,0), fx=ratio, fy=ratio)\n",
    "    return im\n",
    "\n",
    "\n",
    "# Test images are obtained on https://www.pexels.com/\n",
    "im = cv2.imread(r\"C:\\Users\\jason\\Facial-Recognition-FaceNet-master\\database\\id\\eric.jpg\")[..., ::-1]\n",
    "im = resize_image(im) # Resize image to prevent GPU OOM.\n",
    "bboxes, landmarks = fd.detect_face(im, with_landmarks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135bcb8",
   "metadata": {},
   "source": [
    "## landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "if not webcam.isOpened():\n",
    "    sys.exit(\"Could not open webcam, please open the camera!\")\n",
    "count = 0\n",
    "while True:\n",
    "    count= count+1\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()     \n",
    "    frame_size = frame.shape\n",
    "    face, landmarks = fd.detect_face(frame, with_landmarks=True)\n",
    "\n",
    "    number = len(face)\n",
    "    \n",
    "    if number!=0:\n",
    "        \n",
    "        print(f\"detect {number} face(s)!\")\n",
    "        print(face)\n",
    "        print(\" \")\n",
    "        print(\"landmarks:\",landmarks)\n",
    "        \n",
    "        for i in range(number):\n",
    "            \n",
    "            for j in range(len(landmarks[i])): \n",
    "                \n",
    "                x, y = landmarks[i][j]\n",
    "                cv2.circle(frame, (int(y), int(x)), 3, (0,255,0), -1) \n",
    "      \n",
    "    else:\n",
    "        \n",
    "        print(\"do not detect face(s))!\")\n",
    "\n",
    "    cv2.namedWindow(\"demo\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"demo\", frame)\n",
    "\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca627ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[1])\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dc3f5",
   "metadata": {},
   "source": [
    "## face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "shrink_frame_scale=0.25\n",
    "recover_size = lambda x: x*(int(1/shrink_frame_scale))\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "if not webcam.isOpened():\n",
    "    sys.exit(\"Could not open webcam, please open the camera!\")\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()     \n",
    "    frame_size = frame.shape\n",
    "    \n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=shrink_frame_scale, fy=shrink_frame_scale)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "    bboxes = fd.detect_face(small_frame, with_landmarks=False)\n",
    "    \n",
    "    number0 = len(bboxes)\n",
    "    number = len(bboxes[0])\n",
    "    \n",
    "    print(bboxes)\n",
    "    \n",
    "    if number!=0:\n",
    "   \n",
    "        for i in range(number0):\n",
    "            \n",
    "             # Display detected face\n",
    "            x0, y0, x1, y1, score = bboxes[i] \n",
    "            x0, y0, x1, y1 = map(int, [x0, y0, x1, y1])\n",
    "\n",
    "            crop_face = small_frame[x0:x1, y0:y1, :]\n",
    "\n",
    "            x0, y0, x1, y1 = map(recover_size,  [x0, y0, x1, y1])\n",
    "            print(x0,y0,x1,y1)\n",
    "            cv2.rectangle(frame, (y0,x0), (y1,x1), (0,255,0), 2)\n",
    "  \n",
    "    else:\n",
    "        print(\"No face detected.\")\n",
    "        \n",
    "        \n",
    "    cv2.namedWindow(\"demo\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"demo\", frame)\n",
    "    \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54ca90",
   "metadata": {},
   "source": [
    "## pupil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idet = iris_detector.IrisDetector()\n",
    "idet.set_detector(fd) # fd = face_detector.FaceAlignmentDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12574341",
   "metadata": {},
   "outputs": [],
   "source": [
    "shrink_frame_scale= 0.25\n",
    "recover_scale = int(1/shrink_frame_scale)\n",
    "recover_frame = lambda x: x*(recover_scale)\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "if not webcam.isOpened():\n",
    "    sys.exit(\"Could not open webcam, please open the camera!\")\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()     \n",
    "    frame_size = frame.shape\n",
    "    \n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=shrink_frame_scale, fy=shrink_frame_scale)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "\n",
    "    eye_lms = idet.detect_iris(small_frame)\n",
    "    left = eye_lms[0][0,...]\n",
    "    right = eye_lms[0][1,...]\n",
    "    \n",
    "    print(left)\n",
    "\n",
    "    for i in range(18):\n",
    "        for k in range(2):\n",
    "            left[i,k] = recover_scale*left[i,k]\n",
    "            right[i,k] = recover_scale*right[i,k]\n",
    "    print(left)\n",
    "    frame = idet.draw_pupil(frame, left) # draw left eye\n",
    "    frame = idet.draw_pupil(frame, right) # draw right eye\n",
    "\n",
    "    cv2.namedWindow(\"demo\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"demo\", frame)\n",
    "\n",
    "        # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a401d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb7577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
